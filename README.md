# Awesome_KnowledgeDistillation
è¿™é‡Œæ”¶é›†äº†ä¸€äº›å…³äºçŸ¥è¯†è’¸é¦çš„ä»‹ç»å’Œç ”ç©¶ç°çŠ¶ã€‚æ¬¢è¿ PRï¼å¦‚æœå¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ä¸‰è¿æ”¯æŒğŸ‘ï¼

### DRL åŸºç¡€

- [å¤§ç¥æ€»ç»“ | å¼ºåŒ–å­¦ä¹ çº¿è·¯å›¾](https://mp.weixin.qq.com/s/E2va_w2Lh_x3n_1XnOY0ZA)

### KD æ¦‚è¿°

- [çŸ¥è¯†è’¸é¦ | æ¨¡å‹å‹ç¼©åˆ©å™¨_è‰¯å¿ƒæ€»ç»“](https://zhuanlan.zhihu.com/p/138210881)
- Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks [[paper]](https://arxiv.org/pdf/2004.05937.pdf)

### KD æ–¹æ³•

- PoPS: Policy Pruning and Shrinking for Deep Reinforcement Learning [[paper]](https://arxiv.org/pdf/2001.05012.pdf)

